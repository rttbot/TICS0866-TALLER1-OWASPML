# üí£ Vulnerabilidad ‚Äì LLM04: Denial of Service (DoS)

**L√≠nea 3: Sistemas VQA (MedVQA-AI)**
**Componente foco:** Language Branch + API Interface

***

## 1. Resumen / Definici√≥n

Un ataque **LLM04 - Denial of Service (DoS)** consume una cantidad excesiva de recursos de c√≥mputo (tiempo de GPU/TPU, memoria) al sobrecargar el **Language Branch (LLM)** de **MedVQA-AI** con entradas que son costosas de procesar. El objetivo es paralizar o ralentizar el servicio de inferencia de la API, impidiendo que usuarios leg√≠timos (radi√≥logos) reciban respuestas diagn√≥sticas oportunas. Los ataques t√≠picos incluyen el env√≠o de *prompts* excesivamente largos o forzar la generaci√≥n de respuestas extensas.

## 2. Por qu√© es relevante para MedVQA-AI (Contexto)

En el √°mbito cl√≠nico, la disponibilidad y la baja latencia del sistema VQA son cr√≠ticas para la asistencia diagn√≥stica. La **Language Branch** y el **Generative Model** son los componentes con mayor consumo de recursos. Un DoS exitoso, ya sea por una sola consulta muy larga o por un alto volumen de consultas concurrentes, puede paralizar el servicio de MedVQA-AI.

## 3. Equivalente / mapeo en MITRE ATLAS

* **T√°ctica ATLAS:** **Inhibit Response or Capability** (Inhibir Respuesta o Capacidad).
* **T√©cnica ATLAS:** **Resource Exhaustion** (T1230).

**Justificaci√≥n:** El LLM04 y la t√©cnica ATLAS de Explotaci√≥n de Recursos buscan espec√≠ficamente agotar los recursos de c√≥mputo (GPU/TPU) para interrumpir la disponibilidad del servicio de inferencia de la IA.

***

## 4. Ambiente de Pruebas (Dise√±o, No Ejecuci√≥n)

* **Sandbox Controlado:** Instancia de MedVQA-AI con recursos limitados para simular un cuello de botella.
* **Interfaz API simulada:** Endpoint POST `/vqa/infer`.
* **M√©tricas Clave:** La herramienta de prueba debe poder medir la **latencia** (tiempo de procesamiento), el **consumo de GPU/TPU** y el **n√∫mero de *tokens* generados**.
* **Herramientas:** **Locust** o **JMeter** para simulaci√≥n de carga y concurrencia.

## 5. Componentes Afectados

* **Language Branch (LLM):** Consumidor principal de recursos (GPU/TPU) al realizar la inferencia y la generaci√≥n de texto.
* **API Interface:** Punto de entrada que debe gestionar la cola de solicitudes y aplicar l√≠mites de tasa o longitud de *prompt*.
* **Generative Model (Output Layer):** Puede ser forzado a generar respuestas y reportes m√©dicos excesivamente largos, agotando el tiempo de c√≥mputo.

## 6. Impacto (Qu√© puede pasar)

* **Riesgo Cl√≠nico Alto:** **Denegaci√≥n de Disponibilidad** del servicio. Imposibilidad de recibir diagn√≥sticos o reportes en tiempo real, lo que retrasa la toma de decisiones cr√≠ticas para el paciente.
* **P√©rdida Econ√≥mica:** Altos costos operativos debido al consumo excesivo de GPU/TPU por parte de las consultas maliciosas.
* **Degradaci√≥n del Servicio:** El tiempo de respuesta aumenta a niveles inaceptables (alta latencia), volviendo el sistema inoperativo.

***

## 7. Casos de Prueba (M√≠nimo 3) ‚Äî Dise√±o Conceptual

| Caso | Objetivo | Procedimiento (Resumido) | Evidencia Esperada | Criterio de Riesgo |
| :--- | :--- | :--- | :--- | :--- |
| **A. Ataque de Inferencia Larga (Prompt Length)** | Determinar si el LLM colapsa al procesar *prompts* de longitud excesiva. | 1. **Baseline:** Medir la latencia con un *prompt* est√°ndar (100 *tokens*). 2. **Ataque:** Crear un *prompt* sint√©tico de **10,000 *tokens*** (texto m√©dico repetido + pregunta). 3. **Consultar:** Enviar la imagen y el *prompt* largo. 4. **Analizar:** Registrar la latencia y el consumo de memoria. | La latencia de respuesta aumenta exponencialmente (p. ej., de 1s a 30s+), o la solicitud falla por *timeout*. | **Alto:** Si la latencia se vuelve inaceptable para el uso cl√≠nico. |
| **B. Ataque de Generaci√≥n Larga (Forzar Output)** | Determinar si el LLM puede ser forzado a generar un reporte excesivamente extenso. | 1. **Ataque:** Utilizar un *prompt* dise√±ado para forzar la m√°xima generaci√≥n de *tokens* (p. ej., "¬øEscribe un reporte cl√≠nico detallado de 500 p√°rrafos sobre todos los posibles diagn√≥sticos..."). 2. **Consultar:** Enviar una imagen y el *prompt* de generaci√≥n larga. 3. **Analizar:** Registrar el n√∫mero de *tokens* generados y el tiempo de respuesta. | El sistema genera una respuesta que supera el l√≠mite de longitud de *tokens* establecido (p. ej., 4096 *tokens*), o el tiempo de respuesta se dispara. | **Cr√≠tico:** Si la generaci√≥n de una √∫nica respuesta consume todos los recursos de la GPU/TPU. |
| **C. Ataque Concurrente (Saturaci√≥n de API)** | Simular m√∫ltiples ataques simult√°neos para saturar el *pipeline* de inferencia. | 1. **Baseline:** Medir la capacidad de la API para manejar 10 consultas leg√≠timas/s. 2. **Ataque:** Utilizar **Locust** para inyectar 100 consultas por segundo, cada una con un *prompt* de longitud media-alta. 3. **Analizar:** Registrar el *throughput* y la tasa de error. | El *throughput* cae dr√°sticamente y la tasa de error (errores 5xx) de las solicitudes leg√≠timas aumenta por encima del 5% debido a la saturaci√≥n. | **Grave:** Demuestra que la infraestructura es vulnerable a una Denegaci√≥n de Servicio distribuida (DDoS) a nivel de aplicaci√≥n (Capa 7). |

***

## 8. Herramientas / T√©cnicas Recomendadas

* **Generaci√≥n de Carga:** **Locust** o **JMeter** para simular la concurrencia y la alta tasa de solicitudes.
* **An√°lisis:** Scripts en **Python** para crear *prompts* largos autom√°ticamente y registrar las m√©tricas de latencia.
* **Monitoreo:** Herramientas de monitoreo de infraestructura (**Prometheus/Grafana**) para observar el **uso de GPU/TPU** y la **saturaci√≥n de memoria** durante el ataque.

## 9. Mitigaciones Propuestas (En Prioridad)

1.  **Rate Limiting y Throttling de API:** Implementar l√≠mites estrictos en el **n√∫mero de solicitudes por unidad de tiempo** y por usuario/clave de API.
2.  **L√≠mites de Longitud de *Token*:** Implementar l√≠mites de longitud fijos tanto para la **entrada (*prompt*)** como para la **salida (*generation length*)** en el LLM.
3.  **Filtrado de *Prompts* Repetitivos:** Detectar y descartar *prompts* que contengan patrones de repetici√≥n excesiva (*padding* malicioso).
4.  **Aprovisionamiento de Recursos (Autoscaling):** Utilizar *autoscaling* basado en la longitud de la cola de inferencia para intentar absorber picos leg√≠timos, sin dejar de aplicar *rate limiting* a patrones maliciosos.

## 10. M√©tricas de Evaluaci√≥n (Para el Informe)

* **Latencia Promedio:** Tiempo de respuesta del sistema bajo carga (debe ser estable y bajo).
* **N√∫mero M√°ximo de *Tokens* procesables:** El l√≠mite de *tokens* donde el sistema se vuelve inaceptablemente lento.
* **Tasa de Error (5xx):** Porcentaje de solicitudes fallidas durante el ataque concurrente.

## 11. Consideraciones √âticas y Regulatorias

* **Solo dise√±ar y documentar las pruebas** en un sandbox aislado y con autorizaci√≥n escrita. La ejecuci√≥n de ataques DoS es ilegal sin consentimiento.
* El objetivo es proteger la **disponibilidad** del servicio cl√≠nico, que es un requisito de seguridad fundamental en entornos de salud (HIPAA/normativa local).

**Diagrama de un Ataque DoS contra la API de MedVQA-AI**
![Diagrama de un ataque de Denegaci√≥n de Servicio (DoS) contra el LLM de MedVQA-AI.](grafico3.png)
